{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDaB4JBJdjTv"
      },
      "source": [
        "# Оригинальная модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDsMEzl3Aq5h"
      },
      "outputs": [],
      "source": [
        "# %pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFLGMwlD_DO-",
        "outputId": "3c48023f-a259-4ae6-da0e-82fc08624242"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoImageProcessor, SwinForImageClassification\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "\n",
        "# dataset = load_dataset(\"huggingface/cats-image\")\n",
        "\n",
        "# image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
        "# model = SwinForImageClassification.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED-i9QQKdolK"
      },
      "source": [
        "# Finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVgc-goUgL9a",
        "outputId": "b31c37c3-1798-4c0d-d20c-6afa95586318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "# @title Среда\n",
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUuX1LWCdIGS",
        "outputId": "b9a23f3e-63c5-4447-8d11-65cba2b7174b"
      },
      "outputs": [],
      "source": [
        "# @title Данные\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"mvkvc/artifact-100k\") # subset of ArtiFact labled with \"ai\" and \"real\" tags\n",
        "\n",
        "dataset = dataset.with_format(type=\"torch\", device=device)\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(\"umm-maybe/AI-image-detector\")\n",
        "\n",
        "batch_size = 40\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=dataset[\"train\"], batch_size=batch_size,  num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=dataset[\"test\"], batch_size=batch_size, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'height': 230, 'width': 230}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_processor.do_normalize = True\n",
        "image_processor.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F45gzl72Apkb",
        "outputId": "7a6ee7f4-5718-49c7-e98c-a0794b10cea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Модель загружена\n",
            "SwinForImageClassification(\n",
            "  (swin): SwinModel(\n",
            "    (embeddings): SwinEmbeddings(\n",
            "      (patch_embeddings): SwinPatchEmbeddings(\n",
            "        (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
            "      )\n",
            "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (encoder): SwinEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0): SwinStage(\n",
            "          (blocks): ModuleList(\n",
            "            (0-1): 2 x SwinLayer(\n",
            "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "              (attention): SwinAttention(\n",
            "                (self): SwinSelfAttention(\n",
            "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
            "                  (key): Linear(in_features=128, out_features=128, bias=True)\n",
            "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (output): SwinSelfOutput(\n",
            "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (drop_path): SwinDropPath(p=0.1)\n",
            "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "              (intermediate): SwinIntermediate(\n",
            "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): SwinOutput(\n",
            "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (downsample): SwinPatchMerging(\n",
            "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (1): SwinStage(\n",
            "          (blocks): ModuleList(\n",
            "            (0-1): 2 x SwinLayer(\n",
            "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "              (attention): SwinAttention(\n",
            "                (self): SwinSelfAttention(\n",
            "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
            "                  (key): Linear(in_features=256, out_features=256, bias=True)\n",
            "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (output): SwinSelfOutput(\n",
            "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (drop_path): SwinDropPath(p=0.1)\n",
            "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "              (intermediate): SwinIntermediate(\n",
            "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): SwinOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (downsample): SwinPatchMerging(\n",
            "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
            "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (2): SwinStage(\n",
            "          (blocks): ModuleList(\n",
            "            (0-17): 18 x SwinLayer(\n",
            "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "              (attention): SwinAttention(\n",
            "                (self): SwinSelfAttention(\n",
            "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
            "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
            "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (output): SwinSelfOutput(\n",
            "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (drop_path): SwinDropPath(p=0.1)\n",
            "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "              (intermediate): SwinIntermediate(\n",
            "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): SwinOutput(\n",
            "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (downsample): SwinPatchMerging(\n",
            "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (3): SwinStage(\n",
            "          (blocks): ModuleList(\n",
            "            (0-1): 2 x SwinLayer(\n",
            "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (attention): SwinAttention(\n",
            "                (self): SwinSelfAttention(\n",
            "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (output): SwinSelfOutput(\n",
            "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                  (dropout): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (drop_path): SwinDropPath(p=0.1)\n",
            "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (intermediate): SwinIntermediate(\n",
            "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): SwinOutput(\n",
            "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Sigmoid()\n",
            "    (1): Linear(in_features=1024, out_features=1, bias=True)\n",
            "    (2): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# @title Модель\n",
        "model = SwinForImageClassification.from_pretrained(\"umm-maybe/AI-image-detector\")\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    # torch.nn.Linear(in_features=768, out_features=2, bias=True),\n",
        "    torch.nn.Sigmoid(),\n",
        "    torch.nn.Linear(in_features=1024, out_features=1, bias=True),\n",
        "    torch.nn.Sigmoid()\n",
        "    )\n",
        "model.to(device)\n",
        "print(\"Модель загружена\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kVBRL2TC02XA"
      },
      "outputs": [],
      "source": [
        "# @title EarlyStopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, value=0.99, patience=5):\n",
        "        self.value = value\n",
        "        self.patience = patience\n",
        "        self.wait = 0\n",
        "        self.stopped_epoch = 0\n",
        "        self.best = -float('inf')\n",
        "        self._improved_this_step = False\n",
        "\n",
        "    def improved_this_step(self) -> bool:\n",
        "        return self._improved_this_step\n",
        "\n",
        "    def _condition(self, value) -> bool:\n",
        "        return False\n",
        "\n",
        "    def __call__(self, epoch, value) -> bool:\n",
        "        self._improved_this_step = False\n",
        "        if self._condition(value):\n",
        "            self.best = value\n",
        "            self.wait = 0\n",
        "            self._improved_this_step = True\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                print(f\"Epoch {epoch}: early stopping\")\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "class EarlyStoppingByAccuracy(EarlyStopping):\n",
        "    def _condition(self, value) -> bool:\n",
        "        return value > self.best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "asdzdwXSeOb5",
        "outputId": "5a6a6b3f-a482-4299-d714-fb648e7f97f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bes-s\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch #1/1000..."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bes-s\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\loss.py:101: UserWarning: Using a target size (torch.Size([40, 1, 1])) that is different to the input size (torch.Size([40, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m   writer\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    100\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone training.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 102\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[8], line 80\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m()\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m is_training \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m<\u001b[39m epoch_limit:\n\u001b[0;32m     79\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_limit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 80\u001b[0m   \u001b[43mcalculate_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m   report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     83\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
            "Cell \u001b[1;32mIn[8], line 37\u001b[0m, in \u001b[0;36mcalculate_epoch\u001b[1;34m(writer, epoch, is_train)\u001b[0m\n\u001b[0;32m     34\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 37\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m     38\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output)\n\u001b[0;32m     39\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (output\u001b[38;5;241m.\u001b[39margmax() \u001b[38;5;241m==\u001b[39m targets)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msum()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\models\\swin\\modeling_swin.py:1205\u001b[0m, in \u001b[0;36mSwinForImageClassification.forward\u001b[1;34m(self, pixel_values, head_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;124;03m    Labels for computing the image classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1205\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1213\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1215\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(pooled_output)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\models\\swin\\modeling_swin.py:1012\u001b[0m, in \u001b[0;36mSwinModel.forward\u001b[1;34m(self, pixel_values, bool_masked_pos, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1008\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdepths))\n\u001b[0;32m   1010\u001b[0m embedding_output, input_dimensions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(pixel_values, bool_masked_pos\u001b[38;5;241m=\u001b[39mbool_masked_pos)\n\u001b[1;32m-> 1012\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dimensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1022\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm(sequence_output)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\models\\swin\\modeling_swin.py:837\u001b[0m, in \u001b[0;36mSwinEncoder.forward\u001b[1;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, output_hidden_states, output_hidden_states_before_downsampling, always_partition, return_dict)\u001b[0m\n\u001b[0;32m    828\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    829\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    830\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    834\u001b[0m         always_partition,\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 837\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dimensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_partition\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    842\u001b[0m hidden_states_before_downsampling \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m1\u001b[39m]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\models\\swin\\modeling_swin.py:757\u001b[0m, in \u001b[0;36mSwinStage.forward\u001b[1;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, always_partition)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer_module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[0;32m    755\u001b[0m     layer_head_mask \u001b[38;5;241m=\u001b[39m head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dimensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_partition\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    763\u001b[0m hidden_states_before_downsampling \u001b[38;5;241m=\u001b[39m hidden_states\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\models\\swin\\modeling_swin.py:686\u001b[0m, in \u001b[0;36mSwinLayer.forward\u001b[1;34m(self, hidden_states, input_dimensions, head_mask, output_attentions, always_partition)\u001b[0m\n\u001b[0;32m    684\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_attn_mask(height_pad, width_pad, dtype\u001b[38;5;241m=\u001b[39mhidden_states\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m     attn_mask \u001b[38;5;241m=\u001b[39m \u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states_windows\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    688\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[0;32m    689\u001b[0m     hidden_states_windows, attn_mask, head_mask, output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions\n\u001b[0;32m    690\u001b[0m )\n\u001b[0;32m    692\u001b[0m attention_output \u001b[38;5;241m=\u001b[39m attention_outputs[\u001b[38;5;241m0\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# @title Training loop { display-mode: \"form\" }\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "loss_func = torch.nn.L1Loss()\n",
        "# loss_func = torch.nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.8)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5, verbose=True)\n",
        "\n",
        "import torch\n",
        "import datetime\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "\n",
        "def calculate_epoch(writer: SummaryWriter, epoch, is_train=False):\n",
        "  data_loader = train_loader if is_train else test_loader\n",
        "  if is_train:\n",
        "    model.train(True)\n",
        "  else:\n",
        "    model.eval()\n",
        "\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  avg_loss = 0\n",
        "  batches = 0\n",
        "\n",
        "  for batch_ind, data in enumerate(data_loader):\n",
        "    inputs, targets = data['image'], data['label']\n",
        "    inputs = inputs.permute(0,3,1,2)\n",
        "    inputs, targets = inputs.to(torch.float32).to(device), targets.to(torch.long).to(device)\n",
        "    targets = targets.unsqueeze(1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(inputs).logits\n",
        "    total += len(output)\n",
        "    correct += (output.argmax() == targets).float().sum()\n",
        "\n",
        "    targets = torch.nn.functional.one_hot(targets, num_classes = 1).to(torch.float)\n",
        "    loss = loss_func(output, targets)\n",
        "    \n",
        "    if is_train:\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    avg_loss += loss.item()\n",
        "    batches += 1\n",
        "\n",
        "  avg_loss = avg_loss / batches\n",
        "  accuracy = correct/total\n",
        "\n",
        "  stage = \"train\" if is_train else \"test\"\n",
        "  writer.add_scalar(f\"loss/{stage}\", avg_loss, epoch)\n",
        "  writer.add_scalar(f\"accuracy/{stage}\", accuracy, epoch * total)\n",
        "  if stage == \"train\":\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    writer.add_scalar('Learning Rate', current_lr, epoch)\n",
        "  return {\"acc\": accuracy, \"avg_loss\" : avg_loss}\n",
        "\n",
        "\n",
        "def train_loop():\n",
        "  time_now = datetime.datetime.now()\n",
        "  layout = {\n",
        "      \"Model statistics\" : {\n",
        "      \"loss\": [\"Multiline\", [\"loss/train\", \"loss/test\"]],\n",
        "      \"accuracy\": [\"Multiline\", [\"accuracy/train\", \"accuracy/test\"]],\n",
        "      \"learning_rate\": [\"Scalar\", \"Learning Rate\"]\n",
        "      }\n",
        "  }\n",
        "  writer = SummaryWriter(log_dir=time_now.strftime(\"runs/run %d-%m %H_%M_%S\"))\n",
        "  writer.add_custom_scalars(layout)\n",
        "\n",
        "  early_stop = EarlyStoppingByAccuracy()\n",
        "  epoch_limit = 1000\n",
        "  epoch = 0\n",
        "  is_training = True\n",
        "  while is_training and epoch < epoch_limit:\n",
        "    print(f\"epoch #{epoch+1}/{epoch_limit}...\", end = \"\")\n",
        "    calculate_epoch(writer, epoch, is_train=True)\n",
        "\n",
        "    report = None\n",
        "    with torch.no_grad():\n",
        "      report = calculate_epoch(writer, epoch, is_train=False)\n",
        "      scheduler.step(report[\"avg_loss\"])\n",
        "    if early_stop(epoch, report[\"acc\"]):\n",
        "      is_training = False\n",
        "\n",
        "\n",
        "    if early_stop.improved_this_step():\n",
        "      model.save_pretrained(\"./checkpoints\", safe_serialization=False) # saves as SafeTensors\n",
        "\n",
        "      \n",
        "    print(\"done.\")\n",
        "    writer.flush()\n",
        "    saveser = False\n",
        "    epoch += 1\n",
        "\n",
        "  writer.close()\n",
        "  print('done training.')\n",
        "\n",
        "train_loop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save_pretrained(\"./checkpoints\", safe_serialization=True) # saves as SafeTensors"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TDaB4JBJdjTv",
        "ED-i9QQKdolK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
